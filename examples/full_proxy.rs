use bytes::BytesMut;
/// Full proxy server example - runs a complete HTTP caching proxy
///
/// Run with: cargo run --example full_proxy
/// Test with: curl -x localhost:8888 http://httpbin.org/get
use rustysquid::{create_cache_key, extract_host, is_cacheable, parse_request, ProxyCache};
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::io::{AsyncReadExt, AsyncWriteExt};
use tokio::net::{TcpListener, TcpStream};

const PROXY_PORT: u16 = 8888;

#[tokio::main(flavor = "current_thread")]
async fn main() {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_env_filter("rustysquid=info,full_proxy=info")
        .init();

    println!("üåê RustySquid Full Proxy Example");
    println!("================================");
    println!("Starting proxy server on port {}", PROXY_PORT);
    println!();
    println!("Test commands:");
    println!("  curl -x localhost:{} http://httpbin.org/get", PROXY_PORT);
    println!("  curl -x localhost:{} http://example.com", PROXY_PORT);
    println!();

    let cache = ProxyCache::new();
    let listener = TcpListener::bind(("127.0.0.1", PROXY_PORT))
        .await
        .expect("Failed to bind port");

    let connections = Arc::new(AtomicUsize::new(0));
    let requests = Arc::new(AtomicUsize::new(0));
    let cache_hits = Arc::new(AtomicUsize::new(0));

    println!("‚úÖ Proxy server running on localhost:{}", PROXY_PORT);
    println!("Press Ctrl+C to stop\n");

    loop {
        let (stream, addr) = match listener.accept().await {
            Ok(conn) => conn,
            Err(e) => {
                eprintln!("Failed to accept connection: {}", e);
                continue;
            }
        };

        let cache = cache.clone();
        let conns = connections.clone();
        let reqs = requests.clone();
        let hits = cache_hits.clone();

        conns.fetch_add(1, Ordering::Relaxed);

        let conns_clone = conns.clone();
        let reqs_clone = reqs.clone();
        let hits_clone = hits.clone();

        tokio::spawn(async move {
            println!("üì• New connection from {}", addr);
            handle_client(stream, cache, reqs, hits).await;
            conns_clone.fetch_sub(1, Ordering::Relaxed);

            // Print stats
            println!(
                "üìä Stats - Connections: {}, Requests: {}, Cache hits: {}",
                conns_clone.load(Ordering::Relaxed),
                reqs_clone.load(Ordering::Relaxed),
                hits_clone.load(Ordering::Relaxed)
            );
        });
    }
}

async fn handle_client(
    mut client: TcpStream,
    cache: ProxyCache,
    requests: Arc<AtomicUsize>,
    cache_hits: Arc<AtomicUsize>,
) {
    let mut buffer = BytesMut::with_capacity(8192);

    // Read request
    loop {
        match client.read_buf(&mut buffer).await {
            Ok(0) => return,
            Ok(_) => {
                if buffer.windows(4).any(|w| w == b"\r\n\r\n") {
                    break;
                }
            }
            Err(e) => {
                eprintln!("Error reading request: {}", e);
                return;
            }
        }
    }

    // Parse request
    let (method, path, headers) = match parse_request(&buffer) {
        Some(parsed) => parsed,
        None => {
            eprintln!("Failed to parse request");
            let _ = client.write_all(b"HTTP/1.1 400 Bad Request\r\n\r\n").await;
            return;
        }
    };

    let (host, port) = match extract_host(&headers) {
        Some(h) => h,
        None => {
            eprintln!("No host header found");
            let _ = client.write_all(b"HTTP/1.1 400 Bad Request\r\n\r\n").await;
            return;
        }
    };

    requests.fetch_add(1, Ordering::Relaxed);
    println!("üîç Request: {} {}:{}{}", method, host, port, path);

    // Check cache for GET requests
    let cache_key = create_cache_key(&host, port, &path);

    if method == "GET" {
        if let Some(cached) = cache.get(cache_key).await {
            cache_hits.fetch_add(1, Ordering::Relaxed);
            println!("‚ú® CACHE HIT for {}:{}{}", host, port, path);

            // Send cached response
            let _ = client.write_all(cached.status_line.as_bytes()).await;
            for header in &cached.headers {
                let _ = client.write_all(header.as_bytes()).await;
                let _ = client.write_all(b"\r\n").await;
            }
            let _ = client.write_all(b"\r\n").await;
            let _ = client.write_all(&cached.body).await;
            return;
        }
    }

    println!("üí≠ CACHE MISS for {}:{}{}", host, port, path);

    // For this example, return a simple response
    // In production, you would connect to the upstream server
    let response = format!(
        "HTTP/1.1 200 OK\r\n\
         Content-Type: text/plain\r\n\
         Content-Length: {}\r\n\
         \r\n\
         This is a demo response from the proxy example.\n\
         Method: {}\n\
         Host: {}:{}\n\
         Path: {}\n\
         Cacheable: {}",
        100 + method.len() + host.len() + path.len() + 10,
        method,
        host,
        port,
        path,
        is_cacheable(&method, &path, &[])
    );

    let _ = client.write_all(response.as_bytes()).await;

    // In a real proxy, you would cache the response here if cacheable
    println!("üì§ Sent response to client");
}
